import os
import pandas as pd
import numpy as np
import torch
import pickle
from datetime import datetime
from sklearn.model_selection import train_test_split

# Load metadata CSV
metadata_path = "/home/daisysong/2024-HL-Virtual-Dosimeter/analysis/experiments_info_tables/exp_type-classification/exp-3/metadata.csv"
metadata_df = pd.read_csv(metadata_path)

# Function to load SDO images (placeholder)
def load_sdo_images(input_window_start, input_window_end, sdo_data_dir):
    # List to store loaded images
    sdo_images = []
    # Iterate over the files in the specified directory
    for root, _, files in os.walk(sdo_data_dir):
        for file in files:
            parts = file.split('_')
            if len(parts) < 2:
                continue
            # Extract the timestamp from the filename
            timestamp_str = parts[1]
            try:
                timestamp = datetime.strptime(timestamp_str, '%Y%m%d%H%M')
            except ValueError:
                continue
            # Check if the timestamp is within the input window
            if input_window_start <= timestamp <= input_window_end:
                # Load the image (placeholder for actual image loading)
                image = np.random.randn(224, 224)  # Replace with actual image loading
                sdo_images.append(image)
    return np.stack(sdo_images) if sdo_images else np.array([])

# Function to load radiation dose data (placeholder)
def load_radiation_data(target_window_start, target_window_end, rad_dose_filepath):
    rad_data = pd.read_csv(rad_dose_filepath)
    rad_data['timestamp_utc'] = pd.to_datetime(rad_data['timestamp_utc'])
    mask = (rad_data['timestamp_utc'] >= target_window_start) & (rad_data['timestamp_utc'] <= target_window_end)
    return rad_data.loc[mask, 'absorbed_dose_rate'].values

# Directories
sdo_data_dir = "/home/daisysong/2024-HL-Virtual-Dosimeter/data/google_cloud_buckets/sdoml"
rad_dose_filepath = "/home/daisysong/2024-HL-Virtual-Dosimeter/data/google_cloud_buckets/radlab-private/data_tables/readings_table/per_instrument_padded/CRaTER-D1D2_readings_padded.csv"

# Lists to store all input data and labels
all_sdo_data = []
all_labels = []

# Iterate over each sample in the metadata
for _, row in metadata_df.iterrows():
    input_window_start = pd.to_datetime(row['input_window_start'])
    input_window_end = pd.to_datetime(row['input_window_end'])
    target_window_start = pd.to_datetime(row['target_window_start'])
    target_window_end = pd.to_datetime(row['target_window_end'])

    # Load SDO data
    sdo_data = load_sdo_images(input_window_start, input_window_end, sdo_data_dir)
    all_sdo_data.append(sdo_data)

    # Load radiation dose data
    label_data = load_radiation_data(target_window_start, target_window_end, rad_dose_filepath)
    all_labels.append(label_data)

# Convert lists to numpy arrays
all_sdo_data = np.array(all_sdo_data, dtype=object)  # Use dtype=object to handle arrays of different shapes
all_labels = np.array(all_labels, dtype=object)  # Use dtype=object to handle arrays of different shapes

# Flatten all_labels to avoid multi-dimensional issues in train_test_split
all_labels_flat = np.array([np.mean(label) for label in all_labels])

# Split data into training, validation, and test sets
train_sdo, temp_sdo, train_label, temp_label = train_test_split(all_sdo_data, all_labels_flat, test_size=0.4, random_state=42, stratify=all_labels_flat)
val_sdo, test_sdo, val_label, test_label = train_test_split(temp_sdo, temp_label, test_size=0.5, random_state=42, stratify=temp_label)

# Convert split data back to numpy arrays (not object arrays)
train_sdo = np.array(train_sdo)
val_sdo = np.array(val_sdo)
test_sdo = np.array(test_sdo)
train_label = np.array(train_label)
val_label = np.array(val_label)
test_label = np.array(test_label)

# Save input SDO data to pickle files
train_sdo_path = "/home/daisysong/2024-HL-Virtual-Dosimeter/data/train_sdo.pkl"
val_sdo_path = "/home/daisysong/2024-HL-Virtual-Dosimeter/data/val_sdo.pkl"
test_sdo_path = "/home/daisysong/2024-HL-Virtual-Dosimeter/data/test_sdo.pkl"

with open(train_sdo_path, 'wb') as file:
    pickle.dump(train_sdo, file)
with open(val_sdo_path, 'wb') as file:
    pickle.dump(val_sdo, file)
with open(test_sdo_path, 'wb') as file:
    pickle.dump(test_sdo, file)

# Save label data to pickle files
train_label_path = "/home/daisysong/2024-HL-Virtual-Dosimeter/data/train_label.pkl"
val_label_path = "/home/daisysong/2024-HL-Virtual-Dosimeter/data/val_label.pkl"
test_label_path = "/home/daisysong/2024-HL-Virtual-Dosimeter/data/test_label.pkl"

with open(train_label_path, 'wb') as file:
    pickle.dump(train_label, file)
with open(val_label_path, 'wb') as file:
    pickle.dump(val_label, file)
with open(test_label_path, 'wb') as file:
    pickle.dump(test_label, file)

print(f"Train SDO data saved to {train_sdo_path}")
print(f"Validation SDO data saved to {val_sdo_path}")
print(f"Test SDO data saved to {test_sdo_path}")
print(f"Train labels saved to {train_label_path}")
print(f"Validation labels saved to {val_label_path}")
print(f"Test labels saved to {test_label_path}")


